{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:13:16.104190300Z",
     "start_time": "2023-09-12T18:13:13.492215200Z"
    }
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m desired_columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m무료\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m노블\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m골드\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m블루\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m그린\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m싹틔우미\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmember_yn\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# CSV 파일을 읽어 데이터프레임으로 로드\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseat_table.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 원하는 칼럼만 선택\u001B[39;00m\n\u001B[0;32m      9\u001B[0m selected_df \u001B[38;5;241m=\u001B[39m df[desired_columns]\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    330\u001B[0m     )\n\u001B[1;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    946\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    947\u001B[0m )\n\u001B[0;32m    948\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 950\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    610\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 611\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\u001B[38;5;241m.\u001B[39mread(nrows)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1771\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1772\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1773\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1774\u001B[0m     (\n\u001B[0;32m   1775\u001B[0m         index,\n\u001B[0;32m   1776\u001B[0m         columns,\n\u001B[0;32m   1777\u001B[0m         col_dict,\n\u001B[1;32m-> 1778\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mread(  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m   1779\u001B[0m         nrows\n\u001B[0;32m   1780\u001B[0m     )\n\u001B[0;32m   1781\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1782\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 230\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39mread_low_memory(nrows)\n\u001B[0;32m    231\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    232\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mParserError\u001B[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 추출할 칼럼명 리스트\n",
    "desired_columns = ['무료','노블','골드','블루','그린','싹틔우미','member_yn']\n",
    "\n",
    "# CSV 파일을 읽어 데이터프레임으로 로드\n",
    "df = pd.read_csv('seat_table.csv')\n",
    "\n",
    "# 원하는 칼럼만 선택\n",
    "selected_df = df[desired_columns]\n",
    "\n",
    "# 새로운 CSV 파일로 저장\n",
    "output_file = \"membership_v1.csv\"\n",
    "selected_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"선택한 칼럼을 포함한 파일 '{output_file}'이 생성되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 추출할 칼럼명 리스트\n",
    "desired_columns = ['층','블록','BOX','열','좌석번호']\n",
    "\n",
    "# CSV 파일을 읽어 데이터프레임으로 로드\n",
    "df = pd.read_csv('seat_table.csv')\n",
    "\n",
    "# 원하는 칼럼만 선택\n",
    "selected_df = df[desired_columns]\n",
    "\n",
    "# 새로운 CSV 파일로 저장\n",
    "output_file = \"seat_table_v1.csv\"\n",
    "selected_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"선택한 칼럼을 포함한 파일 '{output_file}'이 생성되었습니다.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:13:16.110176400Z",
     "start_time": "2023-09-12T18:13:16.105189400Z"
    }
   },
   "id": "ad9852b27ea85be1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "\n",
    "# discount_type 열에서 문자열 변경\n",
    "# 파일 경로를 지정하여 CSV 파일을 불러옵니다\n",
    "file_path = 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\booking_table_v1.csv'\n",
    "\n",
    "# CSV 파일을 pandas DataFrame으로 읽어옵니다\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 'discount_type' 열에서 콤마를 제거합니다\n",
    "df['discount_type'] = df['discount_type'].str.replace(',', '')\n",
    "# 변경된 데이터 프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\booking_table_v1_modified.csv', index=False, encoding='utf-8')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T18:13:16.107183900Z"
    }
   },
   "id": "be191886a489cc1e"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-15\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\Users\\\\lgw33\\\\PycharmProjects\\\\aiffel\\\\classic\\\\performance_table_v3.csv')\n",
    "\n",
    "print(df.iloc[0, 6])\n",
    "print(type(df.iloc[0, 6]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:46:08.734873600Z",
     "start_time": "2023-09-12T18:46:07.393245900Z"
    }
   },
   "id": "fbed2937ce0c280e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 경로\n",
    "file_path = 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\customer_table_v1.csv'\n",
    "\n",
    "# 데이터를 로드\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 'age' 열에서 NaN 값을 해당 열의 평균 값으로 채웁니다.\n",
    "mean_age = round(df['age'].mean())\n",
    "df['age'] = df['age'].fillna(mean_age)\n",
    "\n",
    "# 다시 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\customer_table_v2.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T18:13:16.110176400Z"
    }
   },
   "id": "58004c04f6241a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v1.csv')\n",
    "\n",
    "# pre_open_date 및 open_date 컬럼을 문자열로 변환하고 '.0'를 제거\n",
    "df['pre_open_date'] = df['pre_open_date'].astype(str).str.split('.').str[0]\n",
    "df['open_date'] = df['open_date'].astype(str).str.split('.').str[0]\n",
    "\n",
    "# 수정된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v2.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T18:13:16.111173900Z"
    }
   },
   "id": "5fbfb729bb9be914"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v2.csv')\n",
    "\n",
    "# 'nan' 문자열을 numpy nan 객체로 대체 (이렇게 해야 pandas가 NaN으로 인식합니다)\n",
    "df.replace('nan', pd.NA, inplace=True)\n",
    "\n",
    "# 날짜 컬럼에서 NaN 값을 NULL로 대체\n",
    "df['pre_open_date'] = df['pre_open_date'].astype('str').replace('', 'NULL')\n",
    "df['open_date'] = df['open_date'].astype('str').replace('', 'NULL')\n",
    "# pre_open_date 및 open_date 컬럼을 문자열로 변환하고 '.0'를 제거\n",
    "df['pre_open_date'] = df['pre_open_date'].astype(str).str.split('.').str[0]\n",
    "df['open_date'] = df['open_date'].astype(str).str.split('.').str[0]\n",
    "\n",
    "# 수정된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v4.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-12T18:13:16.112171Z"
    }
   },
   "id": "618a41f4fce7e711"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v4.csv')\n",
    "\n",
    "# 'nan' 문자열을 NaN으로 변환\n",
    "df.replace('nan', pd.NA, inplace=True)\n",
    "\n",
    "# pre_open_date 열에서 NaN 값을 찾아 해당 행의 open_date 값으로 대체\n",
    "df['pre_open_date'].fillna(df['open_date'], inplace=True)\n",
    "df['pre_open_date'] = df['pre_open_date'].astype('str').replace('', 'NULL')\n",
    "df['open_date'] = df['open_date'].astype('str').replace('', 'NULL')\n",
    "# pre_open_date 및 open_date 컬럼을 문자열로 변환하고 '.0'를 제거\n",
    "\n",
    "# NaN을 'NULL' 문자열로 다시 변환 (필요한 경우)\n",
    "df.fillna('NULL', inplace=True)\n",
    "\n",
    "# 변환된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v5.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:16:18.015923500Z",
     "start_time": "2023-09-12T18:16:09.976535700Z"
    }
   },
   "id": "38cfc7298b8427b5"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpre_open_date\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mfillna(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopen_date\u001B[39m\u001B[38;5;124m'\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# 변환된 데이터프레임을 새 CSV 파일로 저장\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m df\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mProgramData\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mMySQL\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mMySQL Server 8.0\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mUploads\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mperformance_table_v3.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3720\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[0;32m   3709\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[0;32m   3711\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[0;32m   3712\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[0;32m   3713\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3717\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[0;32m   3718\u001B[0m )\n\u001B[1;32m-> 3720\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrameRenderer(formatter)\u001B[38;5;241m.\u001B[39mto_csv(\n\u001B[0;32m   3721\u001B[0m     path_or_buf,\n\u001B[0;32m   3722\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[0;32m   3723\u001B[0m     sep\u001B[38;5;241m=\u001B[39msep,\n\u001B[0;32m   3724\u001B[0m     encoding\u001B[38;5;241m=\u001B[39mencoding,\n\u001B[0;32m   3725\u001B[0m     errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m   3726\u001B[0m     compression\u001B[38;5;241m=\u001B[39mcompression,\n\u001B[0;32m   3727\u001B[0m     quoting\u001B[38;5;241m=\u001B[39mquoting,\n\u001B[0;32m   3728\u001B[0m     columns\u001B[38;5;241m=\u001B[39mcolumns,\n\u001B[0;32m   3729\u001B[0m     index_label\u001B[38;5;241m=\u001B[39mindex_label,\n\u001B[0;32m   3730\u001B[0m     mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m   3731\u001B[0m     chunksize\u001B[38;5;241m=\u001B[39mchunksize,\n\u001B[0;32m   3732\u001B[0m     quotechar\u001B[38;5;241m=\u001B[39mquotechar,\n\u001B[0;32m   3733\u001B[0m     date_format\u001B[38;5;241m=\u001B[39mdate_format,\n\u001B[0;32m   3734\u001B[0m     doublequote\u001B[38;5;241m=\u001B[39mdoublequote,\n\u001B[0;32m   3735\u001B[0m     escapechar\u001B[38;5;241m=\u001B[39mescapechar,\n\u001B[0;32m   3736\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39mstorage_options,\n\u001B[0;32m   3737\u001B[0m )\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001B[0m, in \u001B[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    210\u001B[0m         kwargs[new_arg_name] \u001B[38;5;241m=\u001B[39m new_arg_value\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[0;32m   1168\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1170\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[0;32m   1171\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[0;32m   1172\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1187\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[0;32m   1188\u001B[0m )\n\u001B[1;32m-> 1189\u001B[0m csv_formatter\u001B[38;5;241m.\u001B[39msave()\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[0;32m   1192\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:241\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[1;32m--> 241\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_handle(\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilepath_or_buffer,\n\u001B[0;32m    243\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    244\u001B[0m     encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    245\u001B[0m     errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merrors,\n\u001B[0;32m    246\u001B[0m     compression\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression,\n\u001B[0;32m    247\u001B[0m     storage_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstorage_options,\n\u001B[0;32m    248\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    249\u001B[0m \n\u001B[0;32m    250\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[0;32m    252\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m    253\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    258\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[0;32m    259\u001B[0m     )\n\u001B[0;32m    261\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    851\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    852\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    853\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    855\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 856\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\n\u001B[0;32m    857\u001B[0m             handle,\n\u001B[0;32m    858\u001B[0m             ioargs\u001B[38;5;241m.\u001B[39mmode,\n\u001B[0;32m    859\u001B[0m             encoding\u001B[38;5;241m=\u001B[39mioargs\u001B[38;5;241m.\u001B[39mencoding,\n\u001B[0;32m    860\u001B[0m             errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[0;32m    861\u001B[0m             newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    862\u001B[0m         )\n\u001B[0;32m    863\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    864\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    865\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v3.csv'"
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:37:33.515451700Z",
     "start_time": "2023-09-12T18:37:31.724335700Z"
    }
   },
   "id": "8d67d6617a22876"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\Users\\\\lgw33\\\\PycharmProjects\\\\aiffel\\\\classic\\\\performance_table_v1.csv', parse_dates=['pre_open_date', 'open_date'])\n",
    "\n",
    "# pre_open_date 열에서 NaN 값을 찾아 해당 행의 open_date 값으로 대체\n",
    "df['pre_open_date'].fillna(df['open_date'], inplace=True)\n",
    "\n",
    "# 변환된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v3.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:38:24.378200600Z",
     "start_time": "2023-09-12T18:38:18.492961900Z"
    }
   },
   "id": "f81dc9d46dd69de0"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\Users\\\\lgw33\\\\PycharmProjects\\\\aiffel\\\\classic\\\\performance_table_v1.csv')\n",
    "\n",
    "# 소수점 형식의 날짜를 YYYYMMDD 형식으로 변환\n",
    "df['pre_open_date'] = pd.to_datetime(df['pre_open_date'].astype(str).str.split('.').str[0], errors='coerce', format='%Y%m%d')\n",
    "df['open_date'] = pd.to_datetime(df['open_date'].astype(str).str.split('.').str[0], errors='coerce', format='%Y%m%d')\n",
    "\n",
    "# pre_open_date 열에서 NaN 값을 찾아 해당 행의 open_date 값으로 대체\n",
    "df['pre_open_date'].fillna(df['open_date'], inplace=True)\n",
    "\n",
    "# 변환된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\Users\\\\lgw33\\\\PycharmProjects\\\\aiffel\\\\classic\\\\performance_table_v3.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:40:21.181849800Z",
     "start_time": "2023-09-12T18:40:07.453405200Z"
    }
   },
   "id": "a3bf531cab4a3703"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_open_date 결측값 개수: 340\n",
      "open_date 결측값 개수: 340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v3.csv', dtype=str)\n",
    "\n",
    "# 날짜 형식으로 변환\n",
    "df['pre_open_date'] = pd.to_datetime(df['pre_open_date'], errors='coerce')\n",
    "df['open_date'] = pd.to_datetime(df['open_date'], errors='coerce')\n",
    "\n",
    "# 각 컬럼의 결측값 개수 계산\n",
    "pre_open_date_na_count = df['pre_open_date'].isna().sum()\n",
    "open_date_na_count = df['open_date'].isna().sum()\n",
    "\n",
    "print(f\"pre_open_date 결측값 개수: {pre_open_date_na_count}\")\n",
    "print(f\"open_date 결측값 개수: {open_date_na_count}\")\n",
    "\n",
    "# 결측값을 다음 행의 값으로 채우기\n",
    "df['pre_open_date'].fillna(method='bfill', inplace=True)\n",
    "df['open_date'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# 다시 'YYYYMMDD' 형식으로 변환\n",
    "df['pre_open_date'] = df['pre_open_date'].dt.strftime('%Y%m%d')\n",
    "df['open_date'] = df['open_date'].dt.strftime('%Y%m%d')\n",
    "\n",
    "# 변환된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v4.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:52:34.069859100Z",
     "start_time": "2023-09-12T18:52:11.341832400Z"
    }
   },
   "id": "37c94e943fc93424"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_open_date 결측값 개수: 340\n",
      "open_date 결측값 개수: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lgw33\\AppData\\Local\\Temp\\ipykernel_30144\\3006855132.py:26: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v4.csv', index=False, line_terminator='\\n')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "df = pd.read_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v3.csv', dtype=str)\n",
    "\n",
    "# 날짜 형식으로 변환\n",
    "df['pre_open_date'] = pd.to_datetime(df['pre_open_date'], errors='coerce')\n",
    "df['open_date'] = pd.to_datetime(df['open_date'], errors='coerce')\n",
    "\n",
    "# 각 컬럼의 결측값 개수 계산\n",
    "pre_open_date_na_count = df['pre_open_date'].isna().sum()\n",
    "open_date_na_count = df['open_date'].isna().sum()\n",
    "\n",
    "print(f\"pre_open_date 결측값 개수: {pre_open_date_na_count}\")\n",
    "print(f\"open_date 결측값 개수: {open_date_na_count}\")\n",
    "\n",
    "# 결측값을 다음 행의 값으로 채우기\n",
    "df['pre_open_date'].fillna(method='bfill', inplace=True)\n",
    "df['open_date'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# 다시 'YYYY-MM-DD' 형식으로 변환\n",
    "df['pre_open_date'] = df['pre_open_date'].dt.strftime('%Y-%m-%d')\n",
    "df['open_date'] = df['open_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 변환된 데이터프레임을 새 CSV 파일로 저장\n",
    "df.to_csv('C:\\\\ProgramData\\\\MySQL\\\\MySQL Server 8.0\\\\Uploads\\\\performance_table_v4.csv', index=False, line_terminator='\\n')\n",
    "# \n",
    "# MySQL에서 나타나는 경고는 CSV 파일이 Windows 환경에서 생성되었기 때문에 발생합니다. Windows는 줄바꿈 문자로 \\r\\n을 사용하는 반면, Linux와 Unix는 \\n만 사용합니다. 따라서 이 경고를 피하려면 CSV 파일을 저장할 때 line_terminator 옵션을 설정하여 줄바꿈 문자를 \\n으로 지정해야 합니다.\n",
    "# \n",
    "# 아래의 코드를 사용하여 CSV 파일을 다시 저장하면 됩니다:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-12T18:57:28.153250700Z",
     "start_time": "2023-09-12T18:57:19.431798700Z"
    }
   },
   "id": "f26a6420973b8c4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8d66ef011c27e660"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
