{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:53:17.654838400Z",
     "start_time": "2023-09-06T06:53:17.639783600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(sklearn.__version__)\n",
    "from pprint import pprint# 줄 간 깔끔하게\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7ff02397ffbb8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:53:18.328895500Z",
     "start_time": "2023-09-06T06:53:18.325395100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c44b919880352c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:53:18.626800700Z",
     "start_time": "2023-09-06T06:53:18.620721400Z"
    }
   },
   "outputs": [],
   "source": [
    "# (2) 데이터 준비\n",
    "# load_digits 메서드를 사용합니다.\n",
    "# \n",
    "# (3) 데이터 이해하기\n",
    "# 지피지기면 백전불태! 다루어야 할 데이터를 자세히 살펴봅시다.\n",
    "# \n",
    "# Feature Data 지정하기\n",
    "# Label Data 지정하기asdasdas\n",
    "# Target Names 출력해 보기\n",
    "# 데이터 Describe 해 보기\n",
    "# (4) train, test 데이터 분리\n",
    "# 모델 학습과 테스트용 문제지와 정답지를 준비해 봅시다.\n",
    "# X_train, X_test, y_train, y_test를 생성하는 방법을 참고해 보세요.\n",
    "# \n",
    "# (5) 다양한 모델로 학습시켜보기\n",
    "# 학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 봅시다. 어떤 모델이 가장 좋은 성능을 보일까요?\n",
    "# \n",
    "# Decision Tree 사용해 보기\n",
    "# Random Forest 사용해 보기\n",
    "# SVM 사용해 보기\n",
    "# SGD Classifier 사용해 보기\n",
    "# Logistic Regression 사용해 보기\n",
    "# (6) 모델을 평가해 보기\n",
    "# 학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요? 모델의 성능을 평가하는 지표로는 무엇이 좋을까요? sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요. 선택하신 이유도 설명해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45ce9a1051a096f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:53:19.122786Z",
     "start_time": "2023-09-06T06:53:19.090139800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'>\n",
      "<class 'str'>\n",
      "('.. _digits_dataset:\\n'\n",
      " '\\n'\n",
      " 'Optical recognition of handwritten digits dataset\\n'\n",
      " '--------------------------------------------------\\n'\n",
      " '\\n'\n",
      " '**Data Set Characteristics:**\\n'\n",
      " '\\n'\n",
      " '    :Number of Instances: 1797\\n'\n",
      " '    :Number of Attributes: 64\\n'\n",
      " '    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n'\n",
      " '    :Missing Attribute Values: None\\n'\n",
      " \"    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n\"\n",
      " '    :Date: July; 1998\\n'\n",
      " '\\n'\n",
      " 'This is a copy of the test set of the UCI ML hand-written digits datasets\\n'\n",
      " 'https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n'\n",
      " '\\n'\n",
      " 'The data set contains images of hand-written digits: 10 classes where\\n'\n",
      " 'each class refers to a digit.\\n'\n",
      " '\\n'\n",
      " 'Preprocessing programs made available by NIST were used to extract\\n'\n",
      " 'normalized bitmaps of handwritten digits from a preprinted form. From a\\n'\n",
      " 'total of 43 people, 30 contributed to the training set and different 13\\n'\n",
      " 'to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n'\n",
      " '4x4 and the number of on pixels are counted in each block. This generates\\n'\n",
      " 'an input matrix of 8x8 where each element is an integer in the range\\n'\n",
      " '0..16. This reduces dimensionality and gives invariance to small\\n'\n",
      " 'distortions.\\n'\n",
      " '\\n'\n",
      " 'For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\n'\n",
      " 'T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\n'\n",
      " 'L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n'\n",
      " '1994.\\n'\n",
      " '\\n'\n",
      " '.. topic:: References\\n'\n",
      " '\\n'\n",
      " '  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n'\n",
      " '    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n'\n",
      " '    Graduate Studies in Science and Engineering, Bogazici University.\\n'\n",
      " '  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n'\n",
      " '  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n'\n",
      " '    Linear dimensionalityreduction using relevance weighted LDA. School of\\n'\n",
      " '    Electrical and Electronic Engineering Nanyang Technological University.\\n'\n",
      " '    2005.\\n'\n",
      " '  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n'\n",
      " '    Algorithm. NIPS. 2000.\\n')\n"
     ]
    }
   ],
   "source": [
    "a=load_digits().keys()  # 구조를 잘 모르겠다. load형 데이터가 Dict 형태로 되어있어서 , \n",
    "print(type(a))\n",
    "b=load_digits().DESCR # key값에 해당하는 str (Value의 형태로서 str)을 불러오는 방식\n",
    "print(type(b))\n",
    "b\n",
    "pprint(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563a395c83756437",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:53:19.948962100Z",
     "start_time": "2023-09-06T06:53:19.932862500Z"
    }
   },
   "outputs": [],
   "source": [
    "digit = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3301121e7b2888f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:52:35.019825800Z",
     "start_time": "2023-09-06T06:52:35.016325200Z"
    }
   },
   "outputs": [],
   "source": [
    "digit_data = digit.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b59355f1fbb4733",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T07:00:03.062006300Z",
     "start_time": "2023-09-06T07:00:02.888780700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_label = digit.target\n",
    "\n",
    "\n",
    "a = digit_label\n",
    "b = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "sns.countplot(x=digit_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6d7a1a40f04f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T02:54:48.934123100Z",
     "start_time": "2023-09-06T02:54:48.931570900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "digit.feature_names\n",
    "print(type(digit.feature_names[0]))\n",
    "print(digit.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a50210cdbdd3e14a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T02:54:49.131507600Z",
     "start_time": "2023-09-06T02:54:49.127627100Z"
    }
   },
   "outputs": [],
   "source": [
    "df_digit = pd.DataFrame(data=digit_data , columns=digit.feature_names) # pixel에 콤마가 찍혀있어서 digit.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8c2c2691e51f07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T02:54:49.424866700Z",
     "start_time": "2023-09-06T02:54:49.347874900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pixel_0_0    pixel_0_1    pixel_0_2    pixel_0_3    pixel_0_4  \\\n",
      "count     1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
      "mean         0.0     0.303840     5.204786    11.835838    11.848080   \n",
      "std          0.0     0.907192     4.754826     4.248842     4.287388   \n",
      "min          0.0     0.000000     0.000000     0.000000     0.000000   \n",
      "25%          0.0     0.000000     1.000000    10.000000    10.000000   \n",
      "50%          0.0     0.000000     4.000000    13.000000    13.000000   \n",
      "75%          0.0     0.000000     9.000000    15.000000    15.000000   \n",
      "max          0.0     8.000000    16.000000    16.000000    16.000000   \n",
      "\n",
      "         pixel_0_5    pixel_0_6    pixel_0_7    pixel_1_0    pixel_1_1  ...  \\\n",
      "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
      "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
      "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
      "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
      "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
      "\n",
      "         pixel_6_6    pixel_6_7    pixel_7_0    pixel_7_1    pixel_7_2  \\\n",
      "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
      "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
      "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
      "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
      "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
      "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
      "\n",
      "         pixel_7_3    pixel_7_4    pixel_7_5    pixel_7_6    pixel_7_7  \n",
      "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
      "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
      "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
      "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
      "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
      "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
      "\n",
      "[8 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_digit.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7aef82a032041eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T03:55:40.129864100Z",
     "start_time": "2023-09-06T03:55:40.121553400Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = int(32)\n",
    "X_train, X_test , y_train, y_test = train_test_split(digit_data,digit_label,test_size=0.2,random_state=idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f5d4dff289a77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:27:19.027298200Z",
     "start_time": "2023-09-06T06:27:18.419998700Z"
    }
   },
   "outputs": [],
   "source": [
    "# (5) 다양한 모델로 학습시켜보기\n",
    "# Decision Tree 사용해 보기\n",
    "dt = DecisionTreeClassifier(random_state=idx)\n",
    "dt.fit(X_train, y_train)\n",
    "# Random Forest 사용해 보기\n",
    "rf = RandomForestClassifier(random_state=idx)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# SVM 사용해 보기\n",
    "svm_model = svm.SVC(random_state=idx)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# SGD Classifier 사용해 보기\n",
    "sgd_model = SGDClassifier(random_state=idx)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression 사용해 보기\n",
    "logistic_model = LogisticRegression(max_iter=4000,random_state=idx)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "models = [dt,rf,svm_model,sgd_model,logistic_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9bb3adb5ed78af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:27:19.671114800Z",
     "start_time": "2023-09-06T06:27:19.629044300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=32)               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        38\n",
      "           1       0.75      0.83      0.79        36\n",
      "           2       0.75      0.84      0.79        32\n",
      "           3       0.92      0.86      0.89        56\n",
      "           4       0.85      0.90      0.88        31\n",
      "           5       0.92      0.97      0.95        36\n",
      "           6       0.97      0.94      0.96        34\n",
      "           7       0.94      0.88      0.91        34\n",
      "           8       0.88      0.78      0.82        27\n",
      "           9       0.79      0.83      0.81        36\n",
      "\n",
      "    accuracy                           0.88       360\n",
      "   macro avg       0.88      0.87      0.87       360\n",
      "weighted avg       0.88      0.88      0.88       360\n",
      "\n",
      "[[34  0  2  0  0  1  0  0  1  0]\n",
      " [ 0 30  4  0  2  0  0  0  0  0]\n",
      " [ 0  2 27  0  0  1  0  0  2  0]\n",
      " [ 0  1  2 48  0  0  0  0  0  5]\n",
      " [ 0  0  0  0 28  0  1  1  0  1]\n",
      " [ 0  0  0  0  0 35  0  0  0  1]\n",
      " [ 0  0  0  0  2  0 32  0  0  0]\n",
      " [ 0  1  1  1  0  0  0 30  0  1]\n",
      " [ 0  4  0  1  0  0  0  1 21  0]\n",
      " [ 0  2  0  2  1  1  0  0  0 30]]\n",
      "RandomForestClassifier(random_state=32)               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       0.97      1.00      0.98        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       0.97      1.00      0.99        34\n",
      "           8       0.96      0.89      0.92        27\n",
      "           9       0.97      1.00      0.99        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "[[38  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 30  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 35  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  0]\n",
      " [ 0  1  1  0  0  0  0  1 24  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n",
      "SVC(random_state=32)               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        27\n",
      "           9       0.95      1.00      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "[[38  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 56  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 30  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 35  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n",
      "SGDClassifier(random_state=32)               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       1.00      0.78      0.88        36\n",
      "           2       1.00      0.97      0.98        32\n",
      "           3       0.98      0.95      0.96        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.97      0.94      0.96        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.75      1.00      0.86        27\n",
      "           9       0.86      1.00      0.92        36\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.96      0.95      0.95       360\n",
      "weighted avg       0.96      0.95      0.95       360\n",
      "\n",
      "[[37  0  0  0  0  1  0  0  0  0]\n",
      " [ 0 28  0  1  0  0  0  0  5  2]\n",
      " [ 0  0 31  0  0  0  0  0  1  0]\n",
      " [ 0  0  0 53  0  0  0  0  2  1]\n",
      " [ 0  0  0  0 30  0  0  0  1  0]\n",
      " [ 0  0  0  0  0 34  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 27  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n",
      "LogisticRegression(max_iter=4000, random_state=32)               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        38\n",
      "           1       0.94      0.94      0.94        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      0.98      0.99        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.94      0.94      0.94        36\n",
      "           6       0.97      1.00      0.99        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.96      0.96      0.96        27\n",
      "           9       0.92      1.00      0.96        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n",
      "[[36  0  0  0  0  2  0  0  0  0]\n",
      " [ 0 34  0  0  0  0  1  0  0  1]\n",
      " [ 0  0 32  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 30  0  0  0  1  0]\n",
      " [ 0  1  0  0  0 34  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 34  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 26  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 36]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accu = []\n",
    "for i, model in enumerate(models):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model,classification_report(y_test,y_pred))\n",
    "    accu.append(( (y_pred == y_test).mean()))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9225d408250d6ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:27:20.599009400Z",
     "start_time": "2023-09-06T06:27:20.596503200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163846b691cd9bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T07:08:26.089078700Z",
     "start_time": "2023-09-06T07:08:25.661733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
      "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
      "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
      "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
      "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
      "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
      "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
      "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
      "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
      "\n",
      "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
      "count     178.000000  178.000000            178.000000       178.000000   \n",
      "mean        2.295112    2.029270              0.361854         1.590899   \n",
      "std         0.625851    0.998859              0.124453         0.572359   \n",
      "min         0.980000    0.340000              0.130000         0.410000   \n",
      "25%         1.742500    1.205000              0.270000         1.250000   \n",
      "50%         2.355000    2.135000              0.340000         1.555000   \n",
      "75%         2.800000    2.875000              0.437500         1.950000   \n",
      "max         3.880000    5.080000              0.660000         3.580000   \n",
      "\n",
      "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \n",
      "count       178.000000  178.000000                    178.000000   178.000000  \n",
      "mean          5.058090    0.957449                      2.611685   746.893258  \n",
      "std           2.318286    0.228572                      0.709990   314.907474  \n",
      "min           1.280000    0.480000                      1.270000   278.000000  \n",
      "25%           3.220000    0.782500                      1.937500   500.500000  \n",
      "50%           4.690000    0.965000                      2.780000   673.500000  \n",
      "75%           6.200000    1.120000                      3.170000   985.000000  \n",
      "max          13.000000    1.710000                      4.000000  1680.000000  \n",
      "[[10  0  0]\n",
      " [ 1  7  2]\n",
      " [ 0  3 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       0.70      0.70      0.70        10\n",
      "           2       0.87      0.81      0.84        16\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.83      0.84      0.83        36\n",
      "weighted avg       0.83      0.83      0.83        36\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "[[ 9  1  0]\n",
      " [ 1  9  0]\n",
      " [ 1 15  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        10\n",
      "           1       0.36      0.90      0.51        10\n",
      "           2       1.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.50        36\n",
      "   macro avg       0.73      0.60      0.46        36\n",
      "weighted avg       0.77      0.50      0.38        36\n",
      "\n",
      "[[10  0  0]\n",
      " [ 4  4  2]\n",
      " [ 7  2  7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        10\n",
      "           1       0.67      0.40      0.50        10\n",
      "           2       0.78      0.44      0.56        16\n",
      "\n",
      "    accuracy                           0.58        36\n",
      "   macro avg       0.64      0.61      0.57        36\n",
      "weighted avg       0.66      0.58      0.57        36\n",
      "\n",
      "[[10  0  0]\n",
      " [ 1  8  1]\n",
      " [ 0  1 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       0.89      0.80      0.84        10\n",
      "           2       0.94      0.94      0.94        16\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.91      0.91        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n",
      "[0.8333333333333334, 0.9722222222222222, 0.5, 0.5833333333333334, 0.9166666666666666]\n"
     ]
    }
   ],
   "source": [
    "load_wine().keys()\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "wine.feature_names\n",
    "print(type(wine.feature_names[0]))\n",
    "print(wine.feature_names)\n",
    "df_wine = pd.DataFrame(data=wine_data, columns=wine.feature_names)  # \n",
    "print(df_wine.describe())\n",
    "idx = int(16)\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=idx)\n",
    "\n",
    "# (5) 다양한 모델로 학습시켜보기\n",
    "# Decision Tree 사용해 보기\n",
    "dt = DecisionTreeClassifier(random_state=idx)\n",
    "dt.fit(X_train, y_train)\n",
    "# Random Forest 사용해 보기\n",
    "rf = RandomForestClassifier(random_state=idx)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# SVM 사용해 보기\n",
    "svm_model = svm.SVC(random_state=idx)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# SGD Classifier 사용해 보기\n",
    "sgd_model = SGDClassifier(random_state=idx)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression 사용해 보기\n",
    "logistic_model = LogisticRegression(max_iter=4000, random_state=idx)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "models = [dt, rf, svm_model, sgd_model, logistic_model]\n",
    "\n",
    "accu = []\n",
    "for i, model in enumerate(models):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accu.append((y_pred == y_test).mean())\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred, zero_division=1))# Iterraion 기본값 100인데 이렇게 했을 때, 2100번값 이상 정도의 큰 값이면 \n",
    "print(accu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed322850eea7bc56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T07:06:08.447535700Z",
     "start_time": "2023-09-06T07:06:08.428132600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_wine().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ce7ee88b99419dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T03:49:50.090334900Z",
     "start_time": "2023-09-06T03:48:00.234738100Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import load_wine\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# \n",
    "# wine = load_wine()\n",
    "# wine_data = wine.data\n",
    "# wine_label = wine.target\n",
    "# \n",
    "# max_iterations = 1000  # 최대 시도 횟수 설정\n",
    "# accuracy_threshold = 1.0  # 원하는 정확도\n",
    "# \n",
    "# for i in range(max_iterations):\n",
    "#     # 데이터를 나눕니다.\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label, test_size=0.2, random_state=32)\n",
    "# \n",
    "#     # 랜덤 포레스트 모델 학습\n",
    "#     rf = RandomForestClassifier()\n",
    "#     rf.fit(X_train, y_train)\n",
    "# \n",
    "#     # 정확도 측정\n",
    "#     y_pred = rf.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "# \n",
    "#     print(f\"Iteration {i + 1}: Accuracy = {accuracy}\")\n",
    "# \n",
    "#     if accuracy == accuracy_threshold:\n",
    "#         print(\"Achieved 100% accuracy!\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc07ec0b0819c155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T05:52:42.611501800Z",
     "start_time": "2023-09-06T05:52:42.263945200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df168553631704b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T06:00:20.789054900Z",
     "start_time": "2023-09-06T06:00:20.095309600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.str_'>\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "       mean radius  mean texture  mean perimeter    mean area  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
      "count     569.000000              569.000000  ...    569.000000   \n",
      "mean        0.181162                0.062798  ...     16.269190   \n",
      "std         0.027414                0.007060  ...      4.833242   \n",
      "min         0.106000                0.049960  ...      7.930000   \n",
      "25%         0.161900                0.057700  ...     13.010000   \n",
      "50%         0.179200                0.061540  ...     14.970000   \n",
      "75%         0.195700                0.066120  ...     18.790000   \n",
      "max         0.304000                0.097440  ...     36.040000   \n",
      "\n",
      "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
      "count     569.000000       569.000000   569.000000        569.000000   \n",
      "mean       25.677223       107.261213   880.583128          0.132369   \n",
      "std         6.146258        33.602542   569.356993          0.022832   \n",
      "min        12.020000        50.410000   185.200000          0.071170   \n",
      "25%        21.080000        84.110000   515.300000          0.116600   \n",
      "50%        25.410000        97.660000   686.500000          0.131300   \n",
      "75%        29.720000       125.400000  1084.000000          0.146000   \n",
      "max        49.540000       251.200000  4254.000000          0.222600   \n",
      "\n",
      "       worst compactness  worst concavity  worst concave points  \\\n",
      "count         569.000000       569.000000            569.000000   \n",
      "mean            0.254265         0.272188              0.114606   \n",
      "std             0.157336         0.208624              0.065732   \n",
      "min             0.027290         0.000000              0.000000   \n",
      "25%             0.147200         0.114500              0.064930   \n",
      "50%             0.211900         0.226700              0.099930   \n",
      "75%             0.339100         0.382900              0.161400   \n",
      "max             1.058000         1.252000              0.291000   \n",
      "\n",
      "       worst symmetry  worst fractal dimension  \n",
      "count      569.000000               569.000000  \n",
      "mean         0.290076                 0.083946  \n",
      "std          0.061867                 0.018061  \n",
      "min          0.156500                 0.055040  \n",
      "25%          0.250400                 0.071460  \n",
      "50%          0.282200                 0.080040  \n",
      "75%          0.317900                 0.092080  \n",
      "max          0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "[[36  3]\n",
      " [13 62]]\n",
      "DecisionTreeClassifier(random_state=10)               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.82        39\n",
      "           1       0.95      0.83      0.89        75\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.84      0.87      0.85       114\n",
      "weighted avg       0.88      0.86      0.86       114\n",
      "\n",
      "[[39  0]\n",
      " [ 2 73]]\n",
      "RandomForestClassifier(random_state=10)               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        39\n",
      "           1       1.00      0.97      0.99        75\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.99      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "[[32  7]\n",
      " [ 2 73]]\n",
      "SVC(random_state=10)               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88        39\n",
      "           1       0.91      0.97      0.94        75\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "[[35  4]\n",
      " [ 8 67]]\n",
      "SGDClassifier(random_state=10)               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        39\n",
      "           1       0.94      0.89      0.92        75\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "[[38  1]\n",
      " [ 4 71]]\n",
      "LogisticRegression(max_iter=4000, random_state=10)               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        39\n",
      "           1       0.99      0.95      0.97        75\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cancer = load_breast_cancer()\n",
    "cancer_data = cancer.data\n",
    "cancer_label = cancer.target\n",
    "cancer.feature_names\n",
    "print(type(cancer.feature_names[0]))\n",
    "print(cancer.feature_names)\n",
    "df_cancer = pd.DataFrame(data=cancer_data, columns=cancer.feature_names)  # \n",
    "print(df_cancer.describe())\n",
    "idx = int(10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data, cancer_label, test_size=0.2, random_state=idx)\n",
    "\n",
    "# (5) 다양한 모델로 학습시켜보기\n",
    "# Decision Tree 사용해 보기\n",
    "dt = DecisionTreeClassifier(random_state=idx)\n",
    "dt.fit(X_train, y_train)\n",
    "# Random Forest 사용해 보기\n",
    "rf = RandomForestClassifier(random_state=idx)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# SVM 사용해 보기\n",
    "svm_model = svm.SVC(random_state=idx)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# SGD Classifier 사용해 보기\n",
    "sgd_model = SGDClassifier(random_state=idx)\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression 사용해 보기\n",
    "logistic_model = LogisticRegression(max_iter=4000, random_state=idx)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "models = [dt, rf, svm_model, sgd_model, logistic_model]\n",
    "\n",
    "accu = []\n",
    "for i, model in enumerate(models):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accu.append(((y_pred == y_test).mean()))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(model, classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d16fd9875f83a9a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 모델 선택과 근거\n",
    "\n",
    "### 1. Logistic Regression\n",
    "- **근거**:\n",
    "  - 로지스틱 회귀는 분류 문제에서 기본적으로 사용되는 선형 분류기 중 하나입니다.\n",
    "  - 데이터에 대한 간단한 인사이트를 얻을 수 있습니다.\n",
    "  - 튜닝할 파라미터가 상대적으로 적어 빠르게 결과를 얻을 수 있습니다.\n",
    "\n",
    "### 2. Decision Tree\n",
    "- **근거**:\n",
    "  - 결정 트리는 데이터의 비선형 관계를 잘 표현할 수 있습니다.\n",
    "  - 결과를 시각화해서 이해하기 쉽습니다.\n",
    "  - 특성 중요도를 확인할 수 있어 데이터에 대한 인사이트 제공에 도움이 됩니다.\n",
    "\n",
    "### 3. Random Forest\n",
    "- **근거**:\n",
    "  - 랜덤 포레스트는 결정 트리의 앙상블 버전입니다.\n",
    "  - 오버피팅 문제를 줄이고 일반화 성능을 향상시킬 수 있습니다.\n",
    "  - 결정 트리보다 튜닝할 파라미터가 더 많지만, 대부분의 경우 더 나은 성능을 보입니다.\n",
    "\n",
    "### 4. SVM (Support Vector Machine)\n",
    "- **근거**:\n",
    "  - SVM은 선형 및 비선형 분류에 모두 사용될 수 있습니다.\n",
    "  - 여러 커널 트릭을 사용하여 데이터의 복잡한 패턴을 학습할 수 있습니다.\n",
    "  - SVM은 특히 높은 차원의 데이터에서 잘 작동하며, 분리 경계 주변의 데이터 포인트에 민감합니다.\n",
    "\n",
    "### 5. SGD Classifier\n",
    "- **근거**:\n",
    "  - SGD(Stochastic Gradient Descent) 분류기는 큰 데이터셋에서 빠르게 결과를 얻기 위해 사용됩니다.\n",
    "  - 로지스틱 회귀나 SVM의 대안으로 사용될 수 있지만, 학습률 및 정규화와 같은 튜닝이 필요한 파라미터가 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c0b51aede0c97c",
   "metadata": {},
   "source": [
    "\n",
    "--\n",
    "\n",
    "## 평가 지표\n",
    "\n",
    "### 1. Accuracy (정확도)\n",
    "- **정의**: 전체 예측 중 올바른 예측의 비율을 나타냅니다.\n",
    "- **적용 상황**: 다중 클래스 분류 문제에서 각 클래스의 표본 수가 균등할 때 주로 사용됩니다. - \n",
    "- #### 확인해보자\n",
    "### OUT76 확인바람\n",
    "\n",
    "- **특징**: 손글씨 인식과 같은 상황에서 각 클래스(숫자)가 균등하게 나타날 확률이 있을 때, 정확도는 가장 직관적인 성능 평가 지표가 될 수 있습니다.\n",
    "#와인 accuracy[0.8333333333333334, 0.9722222222222222, 0.5, 0.5833333333333334, 0.9166666666666666] 위의 평가 모델 순\n",
    "- 의사결정 나무와 SGD 분류기의 정확도가 높게 나옴.\n",
    " - wine 분류에서는 \n",
    "### 2. Confusion Matrix (혼동 행렬)\n",
    "- **정의**: 실제 클래스와 예측 클래스 간의 관계를 표로 나타낸 것입니다.\n",
    "- **적용 상황**: 모델의 세부 성능을 분석할 필요가 있을 때 사용됩니다.\n",
    "- **특징**: 특정 클래스가\n",
    " - 다른 클래스로 얼마나 잘못 분류되는지, 어떤 클래스들이 주로 혼동되는지 등의 정보를 제공합니다.\n",
    "\n",
    "### 3. F1 Score, Precision, Recall\n",
    "- **정의**: \n",
    "  - **Precision**: True Positive를 Positive로 예측한 총 수로 나눈 값.\n",
    "  - **Recall**: True Positive를 실제 Positive의 총 수로 나눈 값.\n",
    "  - **F1 Score**: Precision과 Recall의 조화 평균.\n",
    "- **적용 상황**: 클래스 간 불균형이 존재하거나, 특정 클래스의 성능에 더 중점을 둘 필요가 있을 때 사용됩니다.\n",
    "- **특징**: 높은 Precision은 False Positive가 낮다는 것을 의미하며, 높은 Recall은 False Negative가 낮다는 것을 의미합니다. F1 Score는 이 두 지표의 균형을 나타내므로, 한쪽으로 치우치지 않는 성능을 나타내기 위해 사용됩니다.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7289e3315d25a",
   "metadata": {},
   "source": [
    "### 데이터 탐색 및 이해\n",
    "\n",
    "- **데이터의 구조 파악**: `load_digits()` 함수를 사용하여 데이터를 불러올 때, 데이터의 구조를 처음에는 잘 모르겠었다. `load` 형태의 데이터가 사전(Dict) 형태로 구성되어 있음을 알게 되었다.\n",
    "    ```python\n",
    "    a = load_digits().keys()\n",
    "    print(type(a))\n",
    "    ```\n",
    "  \n",
    "- **데이터 상세 정보**: `DESCR` key를 이용하여 데이터에 대한 상세 정보를 가져왔다. 처음에는 이 key 값에 해당하는 문자열(value)을 어떻게 불러올 지 고민했는데, 구글링을 통해 방법을 찾아냈다. \n",
    "    ```python\n",
    "    b = load_digits().DESCR\n",
    "    ```\n",
    "  \n",
    "- **데이터 시각화**: `pprint`를 통해 데이터의 설명(`DESCR`)을 보기 좋게 시각화할 수 있었다. 줄 간격이 적절히 배치되어 있어 내용을 더 쉽게 이해할 수 있었다.\n",
    "\n",
    "### 평가 지표와 모델 선정\n",
    "\n",
    "- 다양한 평가 지표들 중 어떤 것을 우선시할지는 상황과 문제의 특성에 따라 다르다. 예를 들어, 유방암 검사에서는 False Positive가 발생하는 것이 False Negative에 비해 훨씬 안전하다. 이러한 경우, F1 Score만을 최우선으로 고려하는 것은 적절하지 않을 수 있다.\n",
    "\n",
    "- 와인과 손글씨 데이터에서는 F1 Score를 중요시했지만, 다른 상황에서는 다른 지표가 더 중요할 수 있다. 이처럼, 상황과 데이터의 특성에 따라 적절한 평가 지표를 선택하는 것이 중요하다.\n",
    "\n",
    "### 마무리\n",
    "\n",
    "상황에 따라 적절한 모델과 평가 지표를 선택하는 능력은 데이터 과학자로서 매우 중요한 역량 중 하나다. 이번 경험을 통해 여러 평가 지표와 그 중요성에 대해 다시 한번 깊이 생각해볼 수 있었다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde33fd7864ab4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
